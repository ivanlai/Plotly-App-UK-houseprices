{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install convertbng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import gdal\n",
    "import json\n",
    "from json import dumps\n",
    "from copy import deepcopy\n",
    "from convertbng.util import convert_lonlat\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely.speedups\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict()\n",
    "\n",
    "cfg['download data']    = False\n",
    "cfg['to save']          = True\n",
    "\n",
    "cfg['start_year']       = 1995\n",
    "cfg['end_year']         = 2020\n",
    "cfg['Years']            = list(range(cfg['start_year'], cfg['end_year']+1))\n",
    "\n",
    "cfg['geodata dir']      = 'input/geoData'\n",
    "cfg['distribution dir'] = 'input/Distribution'\n",
    "cfg['houseprice dir']   = 'input/HousePriceData'\n",
    "cfg['school dir']       = 'input/SchoolData'\n",
    "\n",
    "cfg['pp_raw dir']       = os.path.join(cfg['houseprice dir'], 'Raw')\n",
    "cfg['pp_processed dir'] = os.path.join(cfg['houseprice dir'], 'Processed')\n",
    "\n",
    "cfg['appData dir']      = 'appData'\n",
    "\n",
    "# cfg['process_raw_pp']   = True\n",
    "cfg['process_raw_pp']   = False\n",
    "# cfg['raw price files']  = ['pp-2020.csv']\n",
    "cfg['raw price files']  = ['pp-complete.csv', 'pp-2018.csv', 'pp-2019.csv', 'pp-2020.csv']\n",
    "\n",
    "cfg['price_threshold']  = 10000 #Filter out transactions below this value\n",
    "\n",
    "cfg['tolerance']        = 0.001 #Tolerance threshold for shapely polygons simplification\n",
    "\n",
    "cfg['regions_lookup'] = {   'North East'      : 'North England',                   \n",
    "                            'North West'      : 'North England',                                    \n",
    "                            'East Midlands'   : 'Midlands',\n",
    "                            'West Midlands'   : 'Midlands',\n",
    "                            'Greater London'  : 'Greater London',                    \n",
    "                            'South East'      : 'South East',\n",
    "                            'South West'      : 'South West',\n",
    "                            'Wales'           : 'Wales',\n",
    "                            'Scotland'        : 'Scotland',\n",
    "                            'Northern Ireland': 'Northern Ireland'\n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- appData (dir.)\n",
    "- Data Pre-processing.ipynb\n",
    "- input\n",
    "    |-- Distribution \n",
    "    |-- geoData\n",
    "    |-- SchoolData\n",
    "    |-- HousePriceData\n",
    "            |-- Raw\n",
    "            |-- Processed\n",
    "'''\n",
    "\n",
    "os.makedirs(cfg['appData dir'], exist_ok=True)\n",
    "os.makedirs(cfg['pp_processed dir'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unzip postcode shape files\n",
    "if cfg['download data']:\n",
    "    !wget https://www.opendoorlogistics.com/wp-content/uploads/Data/UK-postcode-boundaries-Jan-2015.zip\n",
    "    !unzip UK-postcode-boundaries-Jan-2015.zip -d input\n",
    "    !rm UK-postcode-boundaries-Jan-2015.zip\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download postcode data\n",
    "if cfg['download data']:\n",
    "    !wget https://www.freemaptools.com/download/full-postcodes/ukpostcodes.zip\n",
    "    !unzip ukpostcodes.zip -d input/geoData\n",
    "    !rm ukpostcodes.zip\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uncomment to download all files (The 1995 - 2017 file is 3.7GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and House paid-price files\n",
    "if cfg['download data']:\n",
    "    !wget http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-2020.csv -P input/HousePriceData/Raw/\n",
    "    !wget http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-2019.csv -P input/HousePriceData/Raw/\n",
    "    !wget http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-2018.csv -P input/HousePriceData/Raw/\n",
    "    !wget http://prod.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv -P input/HousePriceData/Raw/\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Code Data - Lookup dictionaries to speed up processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcodes_df = pd.read_csv(os.path.join(cfg['geodata dir'], 'ukpostcodes.csv'))\n",
    "\n",
    "postcodes = dict()\n",
    "for (postcode, latitude, longitude) in postcodes_df[['postcode', 'latitude', 'longitude']].values:\n",
    "    postcodes[postcode] = [latitude, longitude]\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "\n",
    "postcode_region_df = pd.read_csv(os.path.join(cfg['geodata dir'], 'PostCode Region.csv'))\n",
    "\n",
    "postcode_region = dict()\n",
    "for (prefix, region) in postcode_region_df[['Prefix', 'Region']].values:\n",
    "    postcode_region[prefix] = cfg['regions_lookup'][region]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### House Price Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_postcode(postcodes, x):\n",
    "    if x in postcodes:\n",
    "        return postcodes[x]\n",
    "    else:\n",
    "        return ''    \n",
    "\n",
    "pattern=re.compile(r\"\\d\")\n",
    "def lookup_region(postcode_region, x, pattern=pattern):\n",
    "    m = pattern.search(x)\n",
    "    if m is None:\n",
    "        return ''\n",
    "    else:\n",
    "        x = x[:m.start()]          \n",
    "        if x in postcode_region:\n",
    "            return postcode_region[x]\n",
    "        else:\n",
    "            return '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pp_df(df, postcodes, postcode_region):\n",
    "    col = {1:'Price', 2:'Date', 3:'Post Code', 4:'Property Type', 5:'Old/New', 6:'Duration'}\n",
    "    \n",
    "    df.rename(columns = col, inplace = True)\n",
    "    df.fillna('', inplace=True)\n",
    "    df['Address'] = df[7] + ' ' + df[8] + ' ' + df[9] + ' ' + df[10] + ' ' + df[11] + ' ' + df[12] + ' ' + df[13]\n",
    "    df['Address'] = df['Address'].apply(lambda x: ' '.join(x.split()))    \n",
    "    \n",
    "    cols_to_drop = [col for col in df.columns if isinstance(col, int)]\n",
    "    df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    # Drop suspiciously low house price data: (Note: These have Property Type \"Other\". What is it?) \n",
    "    df = df.loc[df.Price > cfg['price_threshold']]\n",
    "    \n",
    "    # Exclude property type Other (O)\n",
    "    df = df.loc[df['Property Type']!='O']\n",
    "    \n",
    "    # Sort by Date:\n",
    "    df.sort_values(by=['Date'], inplace=True, ignore_index=True)\n",
    "    \n",
    "    # Get Latitude and Longitude by Post Code:\n",
    "    df['Post Code Coords'] = df['Post Code'].apply(lambda x: lookup_postcode(postcodes, x))\n",
    "    \n",
    "    # Get year-month:\n",
    "    df['Year-Month'] = df['Date'].apply(lambda s: s[:7])\n",
    "    df['Year']       = df['Date'].apply(lambda s: s[:4])\n",
    "    df['Month']      = df['Date'].apply(lambda s: s[5:7])\n",
    "    \n",
    "    # Get Post code sector\n",
    "    df['Sector'] =  df['Post Code'].apply(lambda s: s[:s.find(' ')+2])\n",
    "    \n",
    "    # Get Region\n",
    "    df['Region'] = df['Post Code'].apply(lambda s: lookup_region(postcode_region, s))    \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 9.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def process_and_save_houseprice(infile, postcodes, postcode_region):\n",
    "    print(f\"Processing {infile}\")\n",
    "                \n",
    "    df = pd.read_csv(os.path.join(cfg['pp_raw dir'], infile), header=None)\n",
    "    df = clean_pp_df(df, postcodes, postcode_region)\n",
    "    print(f'Number of transactions in {infile}: {len(df) :,}')\n",
    "        \n",
    "    for year in df.Year.unique():        \n",
    "        fname = f'pp-{year}.csv'                   \n",
    "        df[df.Year==year].to_csv(os.path.join(cfg['pp_processed dir'], fname), index=False)  \n",
    "        print(f\"{fname} saved\")\n",
    "    \n",
    "#-------------------------------------------------------#\n",
    "if cfg['process_raw_pp']:\n",
    "    for infile in cfg['raw price files']:           \n",
    "        process_and_save_houseprice(infile, postcodes, postcode_region)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction count in 1995: 791,428\n",
      "Transaction count in 1996: 958,613\n",
      "Transaction count in 1997: 1,088,301\n",
      "Transaction count in 1998: 1,046,548\n",
      "Transaction count in 1999: 1,190,704\n",
      "Transaction count in 2000: 1,125,331\n",
      "Transaction count in 2001: 1,241,785\n",
      "Transaction count in 2002: 1,348,336\n",
      "Transaction count in 2003: 1,233,679\n",
      "Transaction count in 2004: 1,230,885\n",
      "Transaction count in 2005: 1,060,732\n",
      "Transaction count in 2006: 1,325,298\n",
      "Transaction count in 2007: 1,271,602\n",
      "Transaction count in 2008: 649,200\n",
      "Transaction count in 2009: 624,926\n",
      "Transaction count in 2010: 662,919\n",
      "Transaction count in 2011: 660,748\n",
      "Transaction count in 2012: 668,335\n",
      "Transaction count in 2013: 806,108\n",
      "Transaction count in 2014: 971,344\n",
      "Transaction count in 2015: 990,104\n",
      "Transaction count in 2016: 999,686\n",
      "Transaction count in 2017: 989,828\n",
      "Transaction count in 2018: 963,597\n",
      "Transaction count in 2019: 922,052\n",
      "Transaction count in 2020: 304,022\n",
      "Total transaction count: 25,126,111\n",
      "CPU times: user 4min 4s, sys: 1min 2s, total: 5min 7s\n",
      "Wall time: 5min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def load_processed_houseprice_data():\n",
    "    house_price_df = pd.DataFrame()\n",
    "    for year in cfg['Years']:\n",
    "        fname = os.path.join(cfg['pp_processed dir'], f'pp-{str(year)}.csv')       \n",
    "        if os.path.isfile(fname) :\n",
    "            df = pd.read_csv(fname)\n",
    "            house_price_df = pd.concat([house_price_df, df], ignore_index=True)       \n",
    "            print(f'Transaction count in {year}: {len(df) :,}')\n",
    "        \n",
    "    print(f\"Total transaction count: {len(house_price_df) :,}\")    \n",
    "    return house_price_df\n",
    "\n",
    "#----------------------------------------#\n",
    "house_price_df = load_processed_houseprice_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Post Code</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Old/New</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Address</th>\n",
       "      <th>Post Code Coords</th>\n",
       "      <th>Year-Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17000</td>\n",
       "      <td>1995-01-01 00:00</td>\n",
       "      <td>HU5 5NY</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>147 WESTLANDS ROAD HULL HULL KINGSTON UPON HULL HUMBERSIDE</td>\n",
       "      <td>[53.7536744770554, -0.414045315055496]</td>\n",
       "      <td>1995-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>HU5 5</td>\n",
       "      <td>North England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61000</td>\n",
       "      <td>1995-01-01 00:00</td>\n",
       "      <td>CT9 5HW</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>15 WENTWORTH AVENUE WESTBROOK MARGATE THANET KENT</td>\n",
       "      <td>[51.3821987268994, 1.3493702654861102]</td>\n",
       "      <td>1995-01</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>CT9 5</td>\n",
       "      <td>South East</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price              Date Post Code Property Type Old/New Duration  \\\n",
       "0  17000  1995-01-01 00:00   HU5 5NY             T       N        F   \n",
       "1  61000  1995-01-01 00:00   CT9 5HW             D       N        F   \n",
       "\n",
       "                                                      Address  \\\n",
       "0  147 WESTLANDS ROAD HULL HULL KINGSTON UPON HULL HUMBERSIDE   \n",
       "1           15 WENTWORTH AVENUE WESTBROOK MARGATE THANET KENT   \n",
       "\n",
       "                         Post Code Coords Year-Month  Year  Month Sector  \\\n",
       "0  [53.7536744770554, -0.414045315055496]    1995-01  1995      1  HU5 5   \n",
       "1  [51.3821987268994, 1.3493702654861102]    1995-01  1995      1  CT9 5   \n",
       "\n",
       "          Region  \n",
       "0  North England  \n",
       "1     South East  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_price_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sector_df(house_price_df):\n",
    "\n",
    "    P = house_price_df[['Year', 'Sector', 'Price']].groupby(by=['Year', 'Sector']).mean()\n",
    "    V = house_price_df[['Year', 'Sector', 'Price']].groupby(by=['Year', 'Sector']).count()\n",
    "    V.rename(columns={'Price': 'Volume'}, inplace=True)\n",
    "    \n",
    "    P = pd.merge(P, V, how='inner', on=['Year','Sector'])\n",
    "    \n",
    "    P.reset_index(inplace=True)\n",
    "    P = P.loc[P['Sector'] != '']\n",
    "        \n",
    "    # Get Region\n",
    "    P['Region'] = P['Sector'].apply(lambda s: lookup_region(postcode_region, s))\n",
    "    \n",
    "    P['Price'] = P['Price'].apply(lambda s: int(np.round(s/1000)*1000))\n",
    "    P['Display Price'] = P['Price'].apply(lambda x: f\"{int(np.round(x/1000)) :,}K\")\n",
    "    P['text']  = P['Sector'] + '<br>' + 'Avg. Price: ' + P['Display Price'] + '<br>' + 'Sales Volume: ' + P['Volume'].astype(str)\n",
    "    P.drop(columns=['Display Price'], inplace=True)\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 3.07 s, total: 20.6 s\n",
      "Wall time: 20.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Region</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>AL1 1</td>\n",
       "      <td>90000</td>\n",
       "      <td>164</td>\n",
       "      <td>South East</td>\n",
       "      <td>AL1 1&lt;br&gt;Avg. Price: 90K&lt;br&gt;Sales Volume: 164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995</td>\n",
       "      <td>AL1 2</td>\n",
       "      <td>81000</td>\n",
       "      <td>70</td>\n",
       "      <td>South East</td>\n",
       "      <td>AL1 2&lt;br&gt;Avg. Price: 81K&lt;br&gt;Sales Volume: 70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995</td>\n",
       "      <td>AL1 3</td>\n",
       "      <td>89000</td>\n",
       "      <td>94</td>\n",
       "      <td>South East</td>\n",
       "      <td>AL1 3&lt;br&gt;Avg. Price: 89K&lt;br&gt;Sales Volume: 94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995</td>\n",
       "      <td>AL1 4</td>\n",
       "      <td>128000</td>\n",
       "      <td>180</td>\n",
       "      <td>South East</td>\n",
       "      <td>AL1 4&lt;br&gt;Avg. Price: 128K&lt;br&gt;Sales Volume: 180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>AL1 5</td>\n",
       "      <td>73000</td>\n",
       "      <td>173</td>\n",
       "      <td>South East</td>\n",
       "      <td>AL1 5&lt;br&gt;Avg. Price: 73K&lt;br&gt;Sales Volume: 173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Sector   Price  Volume      Region  \\\n",
       "0  1995  AL1 1   90000     164  South East   \n",
       "1  1995  AL1 2   81000      70  South East   \n",
       "2  1995  AL1 3   89000      94  South East   \n",
       "3  1995  AL1 4  128000     180  South East   \n",
       "4  1995  AL1 5   73000     173  South East   \n",
       "\n",
       "                                             text  \n",
       "0   AL1 1<br>Avg. Price: 90K<br>Sales Volume: 164  \n",
       "1    AL1 2<br>Avg. Price: 81K<br>Sales Volume: 70  \n",
       "2    AL1 3<br>Avg. Price: 89K<br>Sales Volume: 94  \n",
       "3  AL1 4<br>Avg. Price: 128K<br>Sales Volume: 180  \n",
       "4   AL1 5<br>Avg. Price: 73K<br>Sales Volume: 173  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sector_df = get_sector_df(house_price_df) \n",
    "sector_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting and saving sector_price by year (for Chropleth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 685 ms, sys: 35.8 ms, total: 720 ms\n",
      "Wall time: 724 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sector_by_year = dict()\n",
    "for year in cfg['Years']:    \n",
    "    sector_by_year[year] = sector_df[sector_df.Year==year].reset_index(drop=True)  \n",
    "    \n",
    "    if cfg['to save']:\n",
    "        fname = os.path.join(cfg['appData dir'], f'sector_price_{year}.csv')\n",
    "        sector_by_year[year].to_csv(fname, index=False)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting and saving sector_percentage_delta by year (for Chropleth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.37 s, sys: 48.8 ms, total: 3.42 s\n",
      "Wall time: 3.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Building sector_price[year] {sector: price} dict for quick lookup\n",
    "sector_price   = dict()\n",
    "for year in cfg['Years']:\n",
    "    sector_price[year] = dict()\n",
    "    for sector, region, price in sector_by_year[year][['Sector', 'Region', 'Price']].values:             \n",
    "        sector_price[year][sector] = [region, price]\n",
    "\n",
    "#-------------------------------#\n",
    "sector_delta = dict()\n",
    "\n",
    "sector_delta[1995] = dict()\n",
    "for sector, [region, price] in sector_price[1995].items():\n",
    "    sector_delta[1995][sector] = [0, region]\n",
    "    \n",
    "for y1, y2 in zip(cfg['Years'][1:], cfg['Years'][:-1]):    \n",
    "    sector_delta[y1] = dict()\n",
    "    for sector, [region, price] in sector_price[y1].items():        \n",
    "        if sector in sector_price[y2]:\n",
    "            last_year_price = sector_price[y2][sector][1]\n",
    "            delta = int(np.round(100 * (price - last_year_price) / last_year_price))\n",
    "            sector_delta[y1][sector] = [delta, region]\n",
    "    \n",
    "#----------------------------------------------#\n",
    "for year in cfg['Years']:\n",
    "    tmp = pd.DataFrame.from_dict(sector_delta[year], orient='index', columns=['Percentage Change', 'Region'])\n",
    "    tmp.reset_index(inplace=True)\n",
    "    tmp.rename(columns={'index':'Sector'}, inplace=True)\n",
    "    tmp['text'] = tmp['Sector'] + '<br>' + 'Price Change: ' + tmp['Percentage Change'].apply(lambda s: str(s)) + '%'\n",
    "    \n",
    "    if cfg['to save']:\n",
    "        fname = os.path.join(cfg['appData dir'], f'sector_percentage_delta_{year}.csv')\n",
    "        tmp.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Price and Volume by Year and Property Type df (For time-series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 1.75 s, total: 16.1 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_price_volume_df(house_price_df):\n",
    "    P = house_price_df[['Year', 'Sector', 'Property Type', 'Price']].groupby(by=['Year', 'Sector', 'Property Type']).count()\n",
    "    P.rename(columns={'Price': 'Count'}, inplace=True)\n",
    "    P.reset_index(inplace=True)\n",
    "    \n",
    "    Q = house_price_df[['Year', 'Sector', 'Property Type', 'Price']].groupby(by=['Year', 'Sector', 'Property Type']).mean()\n",
    "    Q.reset_index(inplace=True)\n",
    "    \n",
    "    P['Average Price'] = Q.Price.values\n",
    "    \n",
    "    P = P.loc[P['Sector'] != '']\n",
    "        \n",
    "    return P\n",
    "    \n",
    "#------------------------------------#\n",
    "price_volume_df = get_price_volume_df(house_price_df)\n",
    "if cfg['to save']:\n",
    "    price_volume_df.to_csv(os.path.join(cfg['appData dir'], 'price_volume.csv'), index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Count</th>\n",
       "      <th>Average Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>AL1 1</td>\n",
       "      <td>D</td>\n",
       "      <td>17</td>\n",
       "      <td>165320.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995</td>\n",
       "      <td>AL1 1</td>\n",
       "      <td>F</td>\n",
       "      <td>55</td>\n",
       "      <td>64719.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995</td>\n",
       "      <td>AL1 1</td>\n",
       "      <td>S</td>\n",
       "      <td>19</td>\n",
       "      <td>91328.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995</td>\n",
       "      <td>AL1 1</td>\n",
       "      <td>T</td>\n",
       "      <td>73</td>\n",
       "      <td>91739.315068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>AL1 2</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>119375.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Sector Property Type  Count  Average Price\n",
       "0  1995  AL1 1             D     17  165320.588235\n",
       "1  1995  AL1 1             F     55   64719.000000\n",
       "2  1995  AL1 1             S     19   91328.947368\n",
       "3  1995  AL1 1             T     73   91739.315068\n",
       "4  1995  AL1 2             D      4  119375.000000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_volume_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regional Price data by year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplify the shapely file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.67 s, sys: 95.6 ms, total: 7.77 s\n",
      "Wall time: 7.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Let's enable speedups to make queries faster\n",
    "shapely.speedups.enable()\n",
    "\n",
    "infile  = os.path.join(cfg['distribution dir'], 'Sectors.shp')\n",
    "outfile = os.path.join(cfg['geodata dir'], 'ukpostcode_geojson.json')\n",
    "\n",
    "shape_gdf = gpd.read_file(infile)\n",
    "\n",
    "polygons = []\n",
    "for x in shape_gdf.geometry.values:\n",
    "    y = x.simplify(cfg['tolerance'], preserve_topology=True)\n",
    "    polygons.append(y)\n",
    "    \n",
    "simplified_shape_gdf = deepcopy(shape_gdf)\n",
    "simplified_shape_gdf['geometry'] = polygons\n",
    "\n",
    "simplified_shape_gdf.to_file(outfile, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No longer needed - the simplified geojson version is much faster to load\n",
    "# Convert Shape file to Geojson    \n",
    "# Code modified from https://github.com/akkana/scripts/blob/master/mapping/polidistmap.py\n",
    "\n",
    "# infile  = os.path.join(cfg['distribution dir'], 'Sectors.shp')\n",
    "# outfile = os.path.join(cfg['geodata dir'], 'ukpostcode_geojson.json')\n",
    "\n",
    "# if not os.path.isfile(outfile):  \n",
    "#     options = gdal.VectorTranslateOptions(format=\"GeoJSON\", dstSRS=\"EPSG:4326\")\n",
    "#     gdal.VectorTranslate(outfile, infile, options=options)\n",
    "#     print(\"Translated GEOJSON file\", outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions: ['North England', 'South East', 'Greater London', 'Midlands', 'South West', 'Wales', 'Scotland']\n"
     ]
    }
   ],
   "source": [
    "regions = [r for r in house_price_df.Region.unique() if isinstance(r, str)]\n",
    "print(f\"Regions: {regions}\")\n",
    "\n",
    "def get_regional_price_data(sector_df, regions):\n",
    "    def inner(region):\n",
    "        if region == 'South East': #Include Greater London in South East graph\n",
    "            mask = (sector_df.Region==region) | (sector_df.Region=='Greater London')\n",
    "            df = sector_df[mask]\n",
    "        else:\n",
    "            df = sector_df[sector_df.Region==region]\n",
    "        return df\n",
    "    \n",
    "    ###########################################\n",
    "    regional_price_data = dict()\n",
    "    \n",
    "    for r in regions:\n",
    "        regional_price_data[r] = inner(r)\n",
    "    \n",
    "    return regional_price_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaking price/volume data up by region:\n",
    "regional_price_data = dict()\n",
    "for year in cfg['Years']:\n",
    "    regional_price_data[year] = get_regional_price_data(sector_by_year[year], regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_geo_data(infile):\n",
    "    with open(infile, \"r\") as read_file:    \n",
    "        geo_data = json.load(read_file)        \n",
    "    return geo_data\n",
    "\n",
    "#---------------------------------------------#\n",
    "infile = os.path.join(cfg['geodata dir'], 'ukpostcode_geojson.json')\n",
    "geo_data = load_geo_data(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Region</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>2018</td>\n",
       "      <td>BR1 1</td>\n",
       "      <td>329000</td>\n",
       "      <td>35</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>BR1 1&lt;br&gt;Avg. Price: 329K&lt;br&gt;Sales Volume: 35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>2018</td>\n",
       "      <td>BR1 2</td>\n",
       "      <td>720000</td>\n",
       "      <td>179</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>BR1 2&lt;br&gt;Avg. Price: 720K&lt;br&gt;Sales Volume: 179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>2018</td>\n",
       "      <td>BR1 3</td>\n",
       "      <td>459000</td>\n",
       "      <td>199</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>BR1 3&lt;br&gt;Avg. Price: 459K&lt;br&gt;Sales Volume: 199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>2018</td>\n",
       "      <td>BR1 4</td>\n",
       "      <td>426000</td>\n",
       "      <td>160</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>BR1 4&lt;br&gt;Avg. Price: 426K&lt;br&gt;Sales Volume: 160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>2018</td>\n",
       "      <td>BR1 5</td>\n",
       "      <td>353000</td>\n",
       "      <td>175</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>BR1 5&lt;br&gt;Avg. Price: 353K&lt;br&gt;Sales Volume: 175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year Sector   Price  Volume          Region  \\\n",
       "719  2018  BR1 1  329000      35  Greater London   \n",
       "720  2018  BR1 2  720000     179  Greater London   \n",
       "721  2018  BR1 3  459000     199  Greater London   \n",
       "722  2018  BR1 4  426000     160  Greater London   \n",
       "723  2018  BR1 5  353000     175  Greater London   \n",
       "\n",
       "                                               text  \n",
       "719   BR1 1<br>Avg. Price: 329K<br>Sales Volume: 35  \n",
       "720  BR1 2<br>Avg. Price: 720K<br>Sales Volume: 179  \n",
       "721  BR1 3<br>Avg. Price: 459K<br>Sales Volume: 199  \n",
       "722  BR1 4<br>Avg. Price: 426K<br>Sales Volume: 160  \n",
       "723  BR1 5<br>Avg. Price: 353K<br>Sales Volume: 175  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regional_price_data[2018]['Greater London'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regional_geo_data(geo_data, postcode_region, regions):\n",
    "    \n",
    "    pattern = re.compile(r\"\\d\")\n",
    "    \n",
    "    def inner(region):\n",
    "        Y = dict()\n",
    "        Y['features'] = []\n",
    "        for k in geo_data.keys():\n",
    "            if k != 'features':\n",
    "                Y[k] = geo_data[k]\n",
    "            else:            \n",
    "                for i, d in enumerate(geo_data['features']):\n",
    "                    for k, v in d.items():\n",
    "                        if k == 'properties':\n",
    "                            sector = v['name']\n",
    "                            m = pattern.search(sector)\n",
    "                            district = sector[:m.start()]\n",
    "                            \n",
    "                            if region == 'South East':\n",
    "                                if postcode_region[district] in [region, 'Greater London']:\n",
    "                                    Y['features'].append(geo_data['features'][i])\n",
    "                            else:\n",
    "                                if postcode_region[district] == region:\n",
    "                                    Y['features'].append(geo_data['features'][i])                                    \n",
    "        return Y\n",
    "        \n",
    "    ###########################################\n",
    "    regional_geo_data = dict()    \n",
    "    for r in regions:\n",
    "        regional_geo_data[r] = inner(r)\n",
    "    \n",
    "    return regional_geo_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 135 ms, sys: 0 ns, total: 135 ms\n",
      "Wall time: 134 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Breaking geo_data up by region:\n",
    "regional_geo_data = get_regional_geo_data(geo_data, postcode_region, regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.4 s, sys: 38.8 ms, total: 2.44 s\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for region, value in regional_geo_data.items():\n",
    "    fname = os.path.join(cfg['appData dir'], f'geodata_{region}.csv')        \n",
    "    with open(fname, \"w\") as f:    \n",
    "        json.dump(value, f)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### School Data\n",
    "https://www.gov.uk/school-performance-tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "regnumber = re.compile(r'\\d+')\n",
    "def num_2_str(x):\n",
    "    if x is not None and regnumber.match(x):\n",
    "        return float(x)\n",
    "    else:\n",
    "        return 0.0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcse_df: (4522, 7)\n",
      "alevel_df: (2624, 7)\n"
     ]
    }
   ],
   "source": [
    "#Import GCSE and ALevel data, filter and basic cleaning\n",
    "\n",
    "fields = ['URN', 'SCHNAME', 'PCODE', 'EGENDER', 'AGERANGE', 'ATT8SCR']\n",
    "gcse_df = pd.read_csv(os.path.join(cfg['school dir'], 'england_ks4final.csv'), usecols=fields, dtype={'URN':str})\n",
    "gcse_df.dropna(inplace=True)\n",
    "gcse_df['ATT8SCR'] = gcse_df['ATT8SCR'].apply(lambda x: num_2_str(x))\n",
    "gcse_df = gcse_df[gcse_df['ATT8SCR']>0]\n",
    "gcse_df.sort_values(by=['ATT8SCR'], ascending=False, ignore_index=True, inplace=True)\n",
    "gcse_df['GCSE rank'] = gcse_df.index+1\n",
    "gcse_df.rename(columns={'EGENDER': 'GENDER'}, inplace=True)\n",
    "\n",
    "print(f\"gcse_df: {gcse_df.shape}\")\n",
    "\n",
    "fields = ['URN', 'SCHNAME', 'PCODE', 'GEND1618', 'AGERANGE', 'TALLPPE_ALEV_1618']\n",
    "alevel_df = pd.read_csv(os.path.join(cfg['school dir'], 'england_ks5final.csv'), usecols=fields, dtype={'URN':str})\n",
    "alevel_df.dropna(inplace=True)\n",
    "alevel_df['TALLPPE_ALEV_1618'] = alevel_df['TALLPPE_ALEV_1618'].apply(lambda x: num_2_str(x))\n",
    "alevel_df = alevel_df[alevel_df['TALLPPE_ALEV_1618']>0]\n",
    "alevel_df.sort_values(by=['TALLPPE_ALEV_1618'], ascending=False, ignore_index=True, inplace=True)\n",
    "alevel_df['A-Level rank'] = alevel_df.index+1\n",
    "alevel_df.rename(columns={'GEND1618': 'GENDER'}, inplace=True)\n",
    "\n",
    "print(f\"alevel_df: {alevel_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(df_x, df_y, key):    \n",
    "    col_x = df_x.columns\n",
    "    col_y = df_y.columns\n",
    "    cols = set(col_x).intersection(set(col_y))\n",
    "    cols.discard(key)\n",
    "    \n",
    "    df_z = df_x.merge(df_y, how='outer', on=key)\n",
    "    \n",
    "    for col in cols:        \n",
    "        tmp = []\n",
    "        C = [f'{col}_x', f'{col}_y']\n",
    "        for a, b in df_z[C].values:            \n",
    "            if isinstance(a, str):\n",
    "                tmp.append(a)\n",
    "            else:\n",
    "                tmp.append(b)\n",
    "        df_z[col] = tmp\n",
    "        df_z.drop(columns=[*C], inplace=True)\n",
    "                    \n",
    "    return df_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge GCSE and ALevel data into school_df\n",
    "school_df = merge_df(gcse_df, alevel_df, 'URN')\n",
    "school_df['GENDER'] = school_df['GENDER'].apply(lambda s: s.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best of GCSE and Alevel Rank:\n",
    "tmp = []\n",
    "for gcse_rank, alevel_rank in school_df[['GCSE rank', 'A-Level rank']].values:\n",
    "    tmp.append(int(np.nanmin([gcse_rank, alevel_rank])))\n",
    "    \n",
    "school_df['Best Rank'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge school status into school_df\n",
    "school_info_df = pd.read_csv(os.path.join(cfg['school dir'], 'england_school_information.csv'), \n",
    "                             dtype={'URN':str})\n",
    "school_df = school_df.merge(school_info_df[['URN', 'MINORGROUP']], how='left', on='URN')\n",
    "school_df.rename(columns={'MINORGROUP':'Status'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge lat, long into school_df\n",
    "fields = ['URN', 'Easting', 'Northing']\n",
    "school_loc_df = pd.read_csv(os.path.join(cfg['geodata dir'], 'EduBase Extract - 2016-0005414.csv'),\n",
    "                            usecols=fields, encoding = \"ISO-8859-1\", dtype={'URN':str})\n",
    "\n",
    "school_df = school_df.merge(school_loc_df[['URN', 'Easting', 'Northing']], how='left', on='URN')\n",
    "school_df = school_df[pd.notna(school_df.Easting) | pd.notna(school_df.Northing)]\n",
    "\n",
    "long, lat = convert_lonlat(school_df.Easting.values, school_df.Northing.values)\n",
    "school_df['Latitude'] = lat\n",
    "school_df['Longitude'] = long\n",
    "school_df.drop(columns=['Easting', 'Northing'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Hover label text\n",
    "tmp = []\n",
    "cols = ['SCHNAME', 'AGERANGE', 'GENDER', 'Status', \n",
    "        'ATT8SCR', 'GCSE rank', 'TALLPPE_ALEV_1618', 'A-Level rank']\n",
    "\n",
    "for row in school_df[cols].values:\n",
    "    text = row[0] + '<br>' + row[1] + ' ' + row[2] + ' ' +  row[3] + ' '\n",
    "    if ~np.isnan(row[4]):\n",
    "        text += '<br>' + 'GCSE: A8S ' + str(row[4]) + ', #' + f\"{int(row[5]) :,}\"\n",
    "    if ~np.isnan(row[6]):\n",
    "        text += '<br>' + 'A-level: APS ' + str(row[6]) + ', #' + f\"{int(row[7]) :,}\"\n",
    "        \n",
    "    tmp.append(text)\n",
    "    \n",
    "school_df['Info'] = tmp\n",
    "\n",
    "cols.remove('ATT8SCR')\n",
    "cols.remove('TALLPPE_ALEV_1618')\n",
    "school_df.drop(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URN</th>\n",
       "      <th>ATT8SCR</th>\n",
       "      <th>TALLPPE_ALEV_1618</th>\n",
       "      <th>PCODE</th>\n",
       "      <th>Best Rank</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138051</td>\n",
       "      <td>85.2</td>\n",
       "      <td>49.25</td>\n",
       "      <td>NW11 7BN</td>\n",
       "      <td>1</td>\n",
       "      <td>51.581087</td>\n",
       "      <td>-0.189161</td>\n",
       "      <td>The Henrietta Barnett School&lt;br&gt;11-18 Girls Academy &lt;br&gt;GCSE: A8S 85.2, #1&lt;br&gt;A-level: APS 49.25, #30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136615</td>\n",
       "      <td>85.1</td>\n",
       "      <td>48.99</td>\n",
       "      <td>KT2 5PL</td>\n",
       "      <td>2</td>\n",
       "      <td>51.425579</td>\n",
       "      <td>-0.302869</td>\n",
       "      <td>The Tiffin Girls' School&lt;br&gt;11-18 Girls Academy &lt;br&gt;GCSE: A8S 85.1, #2&lt;br&gt;A-level: APS 48.99, #35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      URN  ATT8SCR  TALLPPE_ALEV_1618     PCODE  Best Rank   Latitude  \\\n",
       "0  138051     85.2              49.25  NW11 7BN          1  51.581087   \n",
       "1  136615     85.1              48.99   KT2 5PL          2  51.425579   \n",
       "\n",
       "   Longitude  \\\n",
       "0  -0.189161   \n",
       "1  -0.302869   \n",
       "\n",
       "                                                                                                    Info  \n",
       "0  The Henrietta Barnett School<br>11-18 Girls Academy <br>GCSE: A8S 85.2, #1<br>A-level: APS 49.25, #30  \n",
       "1      The Tiffin Girls' School<br>11-18 Girls Academy <br>GCSE: A8S 85.1, #2<br>A-level: APS 48.99, #35  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "school_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 9)\n"
     ]
    }
   ],
   "source": [
    "for n in [500]:\n",
    "    gcse_df = school_df.sort_values(by=['ATT8SCR'], ascending=False, ignore_index=True)[:n]\n",
    "    alevel_df = school_df.sort_values(by=['TALLPPE_ALEV_1618'], ascending=False, ignore_index=True)[:n]\n",
    "    \n",
    "    school_topN = pd.concat([gcse_df, alevel_df])\n",
    "    school_topN.drop_duplicates(subset=['URN'], inplace=True)\n",
    "    school_topN['Region'] = school_topN['PCODE'].apply(lambda x: lookup_region(postcode_region, x))\n",
    "    \n",
    "    print(school_topN.shape)\n",
    "    \n",
    "    school_topN.to_csv(os.path.join(cfg['appData dir'], f'schools_top_{n}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regions = ['South East', 'North England', 'Midlands', 'South West', 'Greater London', 'Wales']\n",
    "\n",
    "for region in Regions:\n",
    "    if region != 'South East':\n",
    "        mask = school_topN.Region==region        \n",
    "    else:\n",
    "        mask = (school_topN.Region=='South East') | (school_topN.Region=='Greater London')    \n",
    "        \n",
    "    school_topN[mask].to_csv(os.path.join(cfg['appData dir'], f'schools_{region}.csv'), index=False)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Data Preparation completed in {(time.time()-t0)/60 :.1f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
